{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "import math\n",
    "import time\n",
    "import h5py\n",
    "import sklearn\n",
    "import copy\n",
    "from sklearn.utils import shuffle\n",
    "from scipy import stats\n",
    "\n",
    "import os\n",
    "\n",
    "print('Tensorflow Version {}'.format(tf.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_notebook=time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HParams(object):\n",
    "    def __init__(self):\n",
    "        self.Lambda = 10\n",
    "        self.batchsize = 50\n",
    "        self.trainingBatchSize = 5\n",
    "        self.thetaBins = 6\n",
    "        self.trainingEpochs = 20\n",
    "        self.adversary_lr = 1e-3\n",
    "        self.classifier_lr = 1e-3\n",
    "\n",
    "HPARAMS = HParams()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifierOnly = False\n",
    "\n",
    "include_features = ['theta', 'tau1', 'tau2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printTime(delta):\n",
    "    \n",
    "    h = (delta // 3600)\n",
    "    m = (delta % 3600) // 60\n",
    "    s = delta % 60\n",
    "    \n",
    "    if (delta > 3600):\n",
    "        print('Time {0:.0f}h {1:.0f}m {2:.2f}s'.format(h, m, s))\n",
    "        \n",
    "    elif (delta > 60):\n",
    "        print('Time {0:.0f}m {1:.2f}s'.format(m, s))\n",
    "    \n",
    "    else:\n",
    "        print('Time {0:.2f}s'.format(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlabels = {\n",
    "'theta':r'$\\Delta \\theta$',\n",
    "'z':r'$\\mathrm{log}(z)$',\n",
    "'radii':r'$r$',\n",
    "'pt':r'$\\mathrm{log}(p_{T})$',\n",
    "'eta':r'$\\eta$',\n",
    "'phi':r'$\\phi$',\n",
    "'mass':r'Mass',\n",
    "'tau1':r'$\\tau_{1}$',\n",
    "'tau2':r'$\\tau_{2}$',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.5\n",
    "\n",
    "def plotFeature(X, Y, feat):\n",
    "    \n",
    "    siglab = Y[:,1]==1\n",
    "    bkglab = Y[:,1]==0\n",
    "    \n",
    "    \n",
    "    \n",
    "    sig = X[feat][siglab].flatten()\n",
    "    bkg = X[feat][bkglab].flatten()\n",
    "    \n",
    "    maximum = np.max([np.max(sig), np.max(bkg)])\n",
    "    minimum = np.min([np.min(sig), np.min(bkg)])\n",
    "    nbins = 50\n",
    "    brange = np.linspace(minimum, maximum, 50)\n",
    "    \n",
    "    \n",
    "    plt.hist(sig, bins=brange, hatch='//', alpha=alpha, label='Signal', density=True)\n",
    "    plt.hist(sig, bins=brange, histtype='step', color='k', density=True)\n",
    "    plt.hist(bkg, bins=brange, hatch='\\\\', alpha=alpha, label='Background', density=True)\n",
    "    plt.hist(bkg, bins=brange, histtype='step', color='k', density=True)\n",
    "    \n",
    "    plt.xlabel(xlabels[feat])\n",
    "    plt.ylabel('Density')\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAdversary(X, X_shift, Y):\n",
    "    \n",
    "    sig = (Y[:,1]==1)\n",
    "    \n",
    "#     xval = X[sig].flatten()\n",
    "#     xval_s = X_shift[sig].flatten()\n",
    "    \n",
    "    xval = X.flatten()\n",
    "    xval_s = X_shift.flatten()\n",
    "\n",
    "    maximum = np.max([np.max(X), np.max(X_shift)])\n",
    "    minimum = np.min([np.min(X), np.min(X_shift)])\n",
    "    nbins = 50\n",
    "    brange = np.linspace(minimum, maximum, 50)\n",
    "\n",
    "    hx = plt.hist(xval, bins=brange, histtype='step', color='k', label=r'$\\Delta \\theta$', density=True)\n",
    "    hxs = plt.hist(xval_s, bins=brange, histtype='step', color='darkgray', label=r'Perturbed $\\Delta \\theta$', density=True)\n",
    "    plt.xlabel(xlabels['theta'])\n",
    "    plt.ylabel('Density')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    hx_height = hx[0]\n",
    "    hxs_height = hxs[0]\n",
    "    height = hx_height-hxs_height\n",
    "    xaxis = hx[1][1:]\n",
    "   \n",
    "    plt.plot(xaxis, height, color='k', linewidth=2, label='Adversary')\n",
    "    plt.xlabel(xlabels['theta'])\n",
    "    plt.ylabel('Density')\n",
    "    plt.legend()\n",
    "    \n",
    "    label_adv = np.ones_like(height)\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    return height, label_adv\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotBin(nBin, xvar, predictions, rows, cols):\n",
    "    \n",
    "    print('plotting bin {}'.format(nBin))\n",
    "    \n",
    "    ycol = ((nBin-1) % cols)\n",
    "    xrow = int(np.floor((nBin-1) // cols))\n",
    "    \n",
    "    ax[xrow][ycol].scatter(xvar, predictions[:,nBin-1])\n",
    "    ax[xrow][ycol].set_xlabel(r'$\\Delta \\theta$')\n",
    "    ax[xrow][ycol].set_ylabel(r'Prediction')\n",
    "    ax[xrow][ycol].set_title('Bin '+str(nBin))\n",
    "    ax[xrow][ycol].set_ylim([0,1])\n",
    "    \n",
    "    \n",
    "        \n",
    "def get_prediction_yvalues(xvar, predictions, norm=False, nBins=10):\n",
    "    \n",
    "    bmin = np.min(xvar)\n",
    "    bmax = np.max(xvar)\n",
    "    brange = np.linspace(bmin, bmax, nBins+1)\n",
    "    \n",
    "    mean, bin_edges, bins = stats.binned_statistic(xvar, predictions, statistic='mean', bins=brange, range=(bmin, bmax))\n",
    "    sums, _, _ = stats.binned_statistic(xvar, predictions, statistic='sum', bins=brange, range=(bmin, bmax))\n",
    "    yerr, _, _ = stats.binned_statistic(xvar, predictions, statistic='std', bins=brange, range=(bmin, bmax))\n",
    "    \n",
    "    # get bin centers\n",
    "    bin_width = (bin_edges[1] - bin_edges[0])\n",
    "    xvals = bin_edges[1:] - bin_width/2\n",
    "    \n",
    "    hmax = np.max(sums)\n",
    "    \n",
    "    yerr = np.sqrt(sums)\n",
    "    \n",
    "    if(norm):\n",
    "        \n",
    "        yvals = mean\n",
    "        \n",
    "        yerr = yerr/hmax\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        yvals = sums\n",
    "        \n",
    "        \n",
    "    \n",
    "    return xvals, yvals, yerr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(\"models\"):\n",
    "    os.mkdir(\"models\")\n",
    "    \n",
    "if not os.path.isdir(\"plots\"):\n",
    "    os.mkdir(\"plots\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_classifier(inputs, concatenated_layers):\n",
    "    \n",
    "        \n",
    "    x = tf.keras.layers.Dense(128, activation='relu')(concatenated_layers)\n",
    "    x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
    "    \n",
    "    \n",
    "    output = tf.keras.layers.Dense(2, activation='softmax', name = 'labels')(x) \n",
    "    model = tf.keras.Model(inputs=inputs, outputs=output, name='Classifier')\n",
    "    \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_adversary(inputs, concatenated_layers):\n",
    "\n",
    "    x = tf.keras.layers.Dense(64, activation='relu', name='Adversary_Dense64_2')(concatenated_layers)\n",
    "    x = tf.keras.layers.Dense(128, activation='relu', name='Adversary_Dense128')(x)\n",
    "\n",
    "    inputs = [input_from_model, feature_input]\n",
    "    output = tf.keras.layers.Dense(HPARAMS.thetaBins, activation='softmax', name = 'output')(x) \n",
    "        \n",
    "    model = tf.keras.Model(inputs=inputs, outputs=output, name='Adversary')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get datasets as dictionaries\n",
    "### Datasets generated with ToyModel/makeFourVectors.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# created by running makeFourVectors.ipynb with addPerturbation = False\n",
    "data_train = np.load('data/jetConstTrain_overlap.npz')\n",
    "data_test = np.load('data/jetConstTest_overlap.npz')\n",
    "\n",
    "# created by running makeFourVectors.ipynb with addPerturbation = True\n",
    "data_train_shift = np.load('data/jetConstTrain_overlap_perturb.npz')\n",
    "data_test_shift = np.load('data/jetConstTest_overlap_perturb.npz')\n",
    "\n",
    "for key, var in data_test.items():\n",
    "    print(var.shape, key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "feat_list = include_features\n",
    "feat_xaug = []\n",
    "\n",
    "Nlist = len(feat_list)\n",
    "Nxaug = len(feat_xaug)\n",
    "\n",
    "nEvents = len(data_train['pt'].flatten())\n",
    "\n",
    "print('Number of particle list features: ', Nlist)\n",
    "print('Number of XAUG features: ', Nxaug)\n",
    "print('N Events: ', nEvents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get datasets as dictionaries\n",
    "\n",
    "X_train = {key: data_train[key] for key in feat_list}\n",
    "X_test = {key: data_test[key] for key in feat_list}\n",
    "\n",
    "X_train_shift = {key: data_train_shift[key] for key in feat_list}\n",
    "X_test_shift = {key: data_test_shift[key] for key in feat_list}\n",
    "\n",
    "# get labels\n",
    "\n",
    "Y_train = data_train['labels']\n",
    "Y_test = data_test['labels']\n",
    "\n",
    "Y_train_shift = data_train_shift['labels']\n",
    "Y_test_shift = data_test_shift['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_names = [key for key in X_train.keys() if not 'labels' in key]\n",
    "layer_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make $\\mathrm{log}(p_{T})$ and $\\mathrm{log}(z)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    X_train['pt'] = np.log(X_train['pt'])\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    X_train['z'] = np.log(X_train['z'])\n",
    "except:\n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    plotFeature(X_train, Y_train, 'theta')\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    plotFeature(X_train, Y_train, 'z')\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    plotFeature(X_train, Y_train, 'radii')\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    plotFeature(X_train, Y_train, 'tau1')\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    plotFeature(X_train, Y_train, 'tau2')\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Signal difference adversary\n",
    "Note: This is not currently used as an input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotFeature(X_train, Y_train, 'theta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotFeature(X_train_shift, Y_train_shift, 'theta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_adv, Y_adv = getAdversary(X_train['theta'], X_train_shift['theta'], Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bin $\\Delta \\theta$\n",
    "`binned_theta` is an input to the adversary model and\n",
    "`theta_labels` are the labels for the adversary model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape theta\n",
    "X_train['theta'] = X_train['theta'][:,0]\n",
    "\n",
    "thetabins = np.linspace(0, 0.3, HPARAMS.thetaBins)\n",
    "binned_theta = np.digitize(X_train['theta'], thetabins) - 1\n",
    "theta_labels = tf.one_hot(binned_theta.squeeze(), HPARAMS.thetaBins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nfirst 5 bins\\n')\n",
    "print(binned_theta[:5])\n",
    "print('\\nfirst 5 labels\\n')\n",
    "print(theta_labels.numpy()[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(X_train['theta'].flatten(), bins=thetabins, histtype='step', density=True)\n",
    "plt.xlabel(r'$\\Delta \\theta$')\n",
    "plt.ylabel('Density')\n",
    "plt.title(r'Binned $\\Delta \\theta$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier and Adversary Training Loop\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, Y_train))\n",
    "train_dataset = train_dataset.batch(HPARAMS.batchsize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_adv = tf.data.Dataset.from_tensor_slices((X_train['theta'], theta_labels))\n",
    "train_dataset_adv = train_dataset_adv.batch(HPARAMS.batchsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_class_fn = tf.keras.losses.CategoricalCrossentropy()\n",
    "loss_adv_fn = tf.keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "\n",
    "optimizer_class=tf.keras.optimizers.Adam(lr=HPARAMS.classifier_lr)\n",
    "optimizer_adv=tf.keras.optimizers.Adam(lr=HPARAMS.adversary_lr)\n",
    "optimizer=tf.keras.optimizers.Adam(lr=HPARAMS.classifier_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_theta = [element[0]['theta'] for element in train_dataset]\n",
    "train_dataset_theta_Y = [element[1] for element in train_dataset_adv]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Loss Function and Custom Gradients\n",
    "\n",
    "### Combined loss of classifier and adversary\n",
    "\n",
    "$$ \\mathcal{L}_{total} = \\mathcal{L}_{classifier} - \\lambda \\mathcal{L}_{adversary} $$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('lambda = {}'.format(HPARAMS.Lambda))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def calc_loss_total(loss_c, loss_a):\n",
    "\n",
    "    # loss_c  - loss of classifier\n",
    "    # loss_a  - loss of adversary\n",
    "    \n",
    "    loss_c = tf.cast(loss_c, 'float32')\n",
    "    loss_a = tf.cast(loss_a, 'float32')\n",
    "\n",
    "    L = tf.math.abs(tf.reduce_mean(loss_c - HPARAMS.Lambda * loss_a))\n",
    "    \n",
    "    return L\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and combine models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inputs for classifier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_inputs = []\n",
    "xlayers = []\n",
    "\n",
    "n = len(layer_names)\n",
    "\n",
    "for i in range(n):\n",
    "\n",
    "    if('theta' in layer_names[i]):\n",
    "        \n",
    "        inpt = tf.keras.Input(shape = (1,), name=layer_names[i])\n",
    "\n",
    "        x = tf.keras.layers.Flatten()(inpt)\n",
    "        classifier_inputs.append(inpt)\n",
    "        xlayers.append(x)\n",
    "\n",
    "        x_dense = tf.keras.layers.Dense(64, activation='relu')(x)\n",
    "        xlayers.append(x_dense)\n",
    "\n",
    "    else:\n",
    "\n",
    "        inpt = tf.keras.Input(shape = (10,1), name=layer_names[i])\n",
    "        x = tf.keras.layers.Flatten()(inpt)\n",
    "\n",
    "        classifier_inputs.append(inpt)\n",
    "        xlayers.append(x) \n",
    "\n",
    "if(n > 1):\n",
    "    concatenated_layers_classifier = tf.keras.layers.concatenate(inputs=xlayers, axis=-1)\n",
    "\n",
    "if(n==1):\n",
    "    classifier_inputs = classifier_inputs[0]\n",
    "\n",
    "classifier_inputs_dict = {c.name:c for c in classifier_inputs}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inputs for adversary model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_from_model = tf.keras.layers.Input(shape = (2,), name='Input')\n",
    "x_input = tf.keras.layers.Flatten()(input_from_model)\n",
    "\n",
    "feature_input = tf.keras.layers.Input(shape = (1,), name='theta_2')\n",
    "x_feature = tf.keras.layers.Flatten()(feature_input)\n",
    "\n",
    "concatenated_layers_adv = tf.keras.layers.concatenate(inputs=[x_feature,x_input], axis=-1)\n",
    "adversary_inputs = [input_from_model, x_feature]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Classifier and Adversary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = build_classifier(classifier_inputs, concatenated_layers_classifier)\n",
    "adversary = build_adversary(adversary_inputs, concatenated_layers_adv)\n",
    "\n",
    "classifier_output = classifier(classifier_inputs)\n",
    "adversary_output = adversary(adversary_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Combined Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_inputs = {**classifier_inputs_dict,\n",
    "            'Input':input_from_model,\n",
    "            'theta_2':feature_input,\n",
    "    }\n",
    "model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Model(\n",
    "    inputs=model_inputs,\n",
    "    outputs={'c_out':classifier_output,\n",
    "             'a_out':adversary_output,\n",
    "            },\n",
    "    \n",
    "    name='Classifier_and_Adversary',\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train adversary for 20 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "classifier.compile(\n",
    "    loss=loss_class_fn,\n",
    "    optimizer=optimizer_class,\n",
    ")\n",
    "\n",
    "adversary.compile(\n",
    "    loss=loss_adv_fn,\n",
    "    optimizer=optimizer_adv,\n",
    ")\n",
    "\n",
    "model.compile(optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "classifierEpochs = 1\n",
    "adversaryEpochs=20\n",
    "\n",
    "if(classifierOnly):\n",
    "    classifierEpochs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.fit(X_train, Y_train, epochs=classifierEpochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Adversary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if(not classifierOnly):\n",
    "    adversary.fit([classifier(X_train), X_train['theta']], theta_labels, epochs=adversaryEpochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {}\n",
    "metrics['loss_class'] = list([])\n",
    "metrics['loss_adv'] = list([])\n",
    "metrics['loss_total'] = list([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to not get thousands of warnings about gradients\n",
    "tf.get_logger().setLevel('ERROR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if (not classifierOnly):\n",
    "    \n",
    "    toPrint=True\n",
    "    last_epoch=time.time()\n",
    "    start_training = time.time()\n",
    "    total_epochs=1\n",
    "\n",
    "\n",
    "    nEpochs = 1\n",
    "\n",
    "    nUpdates_Adversary = 4\n",
    "    nUpdates_Classifier = 5\n",
    "\n",
    "    for ii in range(nEpochs):\n",
    "\n",
    "        start_update=time.time()\n",
    "\n",
    "        try:\n",
    "            del adversary_weights\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "        adversary_weights = copy.deepcopy([adversary.get_layer(layer.name).get_weights() for layer in adversary.layers])\n",
    "\n",
    "        for epoch in range(nUpdates_Classifier):\n",
    "\n",
    "            for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
    "\n",
    "                ### TRAIN CLASSIFIER ###\n",
    "\n",
    "                with tf.GradientTape(persistent=True) as tape_class:\n",
    "\n",
    "                    # adversary output and labels for the batch\n",
    "                    logits_adv = adversary([classifier(x_batch_train), train_dataset_theta[step]])\n",
    "                    preds_adv = train_dataset_theta_Y[step]\n",
    "\n",
    "                    # classifier output for the batch\n",
    "                    logits_class = classifier(x_batch_train) \n",
    "\n",
    "                    # get classifier loss\n",
    "                    loss_class = loss_class_fn(logits_class, y_batch_train)\n",
    "                    \n",
    "                    # get adversary loss\n",
    "                    loss_adv = loss_class_fn(logits_adv, preds_adv)\n",
    "                    tape_class.watch(loss_class)\n",
    "\n",
    "                    # get combined loss\n",
    "                    loss_total = calc_loss_total(loss_class, loss_adv)\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    tape_class.watch(loss_total)\n",
    "                    tape_class.watch(model.trainable_weights)\n",
    "\n",
    "                    # get gradients\n",
    "                    grads = tape_class.gradient(loss_total, model.trainable_weights)            \n",
    "\n",
    "                    # apply gradients\n",
    "                    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "\n",
    "                    tape_class.reset()\n",
    "\n",
    "                    \n",
    "            if(toPrint):\n",
    "\n",
    "\n",
    "                loss_adv = loss_adv_fn(adversary([classifier(X_train), X_train['theta']]), theta_labels)\n",
    "                loss_class = loss_class_fn(classifier(X_train), Y_train)\n",
    "\n",
    "                loss_total = calc_loss_total(loss_class, loss_adv)\n",
    "\n",
    "                print(\"\\nEpoch %d\" % (total_epochs,))\n",
    "                printTime(time.time() - last_epoch)\n",
    "                print('L_class', loss_class.numpy())\n",
    "                print('L_adv', loss_adv.numpy())\n",
    "                print('L_total', loss_total.numpy())\n",
    "                last_epoch = time.time()\n",
    "                \n",
    "                metrics['loss_class'].append(loss_class.numpy())\n",
    "                metrics['loss_adv'].append(loss_adv.numpy())\n",
    "                metrics['loss_total'].append(loss_total.numpy())\n",
    "\n",
    "                total_epochs += 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        end_update = time.time()\n",
    "        printTime(end_update - start_update)\n",
    "\n",
    "\n",
    "\n",
    "        print()\n",
    "\n",
    "    print()\n",
    "    end_training=time.time()\n",
    "    print('\\nTotal time: ', end='')\n",
    "    printTime(end_training - start_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model names \n",
    "\n",
    "model_string = ''\n",
    "for name in layer_names:\n",
    "    model_string += '_' + name\n",
    "if(classifierOnly):\n",
    "    model_string += '_classifierOnly'\n",
    "model_name = 'model' + model_string\n",
    "model_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save models \n",
    "\n",
    "tf.keras.models.save_model(model, f'models/{model_string}.h5')\n",
    "print('saving '+'models/'+model_name+'.h5')\n",
    "if (not classifierOnly):\n",
    "    tf.keras.models.save_model(classifier, f'models/{model_name}_classifier.h5')\n",
    "    tf.keras.models.save_model(adversary, f'models/{model_name}_adversary.h5')\n",
    "\n",
    "    print(f'saving models/{model_name}_classifier.h5')\n",
    "    print(f'saving models/{model_name}_adversary.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots\n",
    "\n",
    "## Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,7.5))\n",
    "x_epochs = np.arange(len(metrics['loss_total']), dtype=int) + 1\n",
    "\n",
    "lw=3\n",
    "\n",
    "cmap = plt.get_cmap('Accent')\n",
    "colors = np.linspace(0,1,9)\n",
    "plt.plot(x_epochs, metrics['loss_total'], lw=lw, color=cmap(colors[0]), label='Loss: Total')\n",
    "# plt.plot(x_epochs, metrics['loss_class'], lw=lw, color=cmap(colors[1]), label='Loss: Classifier')\n",
    "# plt.plot(x_epochs, HPARAMS.Lambda*np.array(metrics['loss_adv']), lw=lw, color=cmap(colors[2]), label='Loss: Adversary')\n",
    "plt.legend(fontsize=15)\n",
    "# plt.ylim(-0.1,10.1)\n",
    "plt.xticks(np.linspace(0,(len(metrics['loss_total']) + len(metrics['loss_total'])%2),1+(len(metrics['loss_total']) + len(metrics['loss_total'])%2)//2, dtype=int), fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.xlabel('Epochs', fontsize=15)\n",
    "plt.ylabel('Loss', fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable dictionaries for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xvars = {name:X_train[name].squeeze() for name in layer_names}\n",
    "\n",
    "for key in xvars.keys():\n",
    "    \n",
    "    if(len(xvars[key].shape) > 1):\n",
    "        xvars[key] = np.average(xvars[key], axis=1)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Model Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = classifier(X_train)\n",
    "predict_adv = adversary([predict, X_train['theta']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uncomment to load saved models instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loaded_model = tf.keras.models.load_model('models/model_theta_tau1_tau2.h5')\n",
    "# loaded_classifier = tf.keras.models.load_model('models/model_theta_tau1_tau2_classifier.h5')\n",
    "# loaded_adversary = tf.keras.models.load_model('models/model_theta_tau1_tau2_adversary.h5')\n",
    "\n",
    "# predict = loaded_classifier(X_train)\n",
    "# predict_adv = loaded_adversary([predict, X_train['theta']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig = predict[Y_train[:,1]==1][:,1].numpy()\n",
    "bkg = predict[Y_train[:,0]==1][:,1].numpy()\n",
    "\n",
    "bins = np.linspace(0, 1, 20)\n",
    "\n",
    "plt.hist(sig, bins, alpha=0.5, label='Signal', density=True)\n",
    "plt.hist(bkg, bins, alpha=0.5, label='Background', density=True)\n",
    "# plt.ylim(0,25000)\n",
    "# plt.yscale('log')\n",
    "plt.legend(loc='upper center')\n",
    "plt.xlabel('Prediction')\n",
    "plt.ylabel('Density')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Model Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = Nlist // 2 + Nlist % 2\n",
    "cols = 2\n",
    "fig, ax = plt.subplots(rows,cols, figsize=(10,4*rows))\n",
    "\n",
    "Title = 'Model Inputs:'\n",
    "for name in layer_names:\n",
    "    Title += ', ' + xlabels[name]\n",
    "    \n",
    "Title = Title.replace(':,', ':')\n",
    "\n",
    "\n",
    "\n",
    "xvals_list = []\n",
    "yvals_list = []\n",
    "yerrs_list = []\n",
    "\n",
    "xvals_list_bkg = []\n",
    "yvals_list_bkg = []\n",
    "yerrs_list_bkg = []\n",
    "\n",
    "for name in layer_names:\n",
    "    \n",
    "    x, y, e = get_prediction_yvalues(xvars[name], predict[:,1])\n",
    "    xb, yb, eb = get_prediction_yvalues(xvars[name], predict[:,0])\n",
    "    \n",
    "    xvals_list.append(x)\n",
    "    yvals_list.append(y)\n",
    "    yerrs_list.append(e)\n",
    "\n",
    "    xvals_list_bkg.append(xb)\n",
    "    yvals_list_bkg.append(yb)\n",
    "    yerrs_list_bkg.append(eb)\n",
    "    \n",
    "    \n",
    "    \n",
    "if (Nlist > 0):\n",
    "    if(Nlist < 2):\n",
    "        ax1 = ax[0]\n",
    "    elif(Nlist < 3):\n",
    "        ax1 = ax[0]\n",
    "    else:\n",
    "        ax1 = ax[0][0]\n",
    "        \n",
    "        \n",
    "if (Nlist > 1):\n",
    "    if(Nlist < 3):\n",
    "        ax2 = ax[1]\n",
    "    else:\n",
    "        ax2 = ax[0][1]\n",
    "        \n",
    "\n",
    "if (Nlist > 2): ax3 = ax[1][0]\n",
    "if (Nlist > 3): ax4 = ax[1][1]\n",
    "if (Nlist > 4): ax5 = ax[2][0]\n",
    "if (Nlist > 5): ax6 = ax[2][1]\n",
    "    \n",
    "    \n",
    "fmt = ''\n",
    "lw = 3\n",
    "\n",
    "if (Nlist > 0):\n",
    "    \n",
    "    ax1.errorbar(xvals_list[0], yvals_list[0], yerr=yerrs_list[0], lw=lw, fmt=fmt)\n",
    "    ax1.errorbar(xvals_list_bkg[0], yvals_list_bkg[0], yerr=yerrs_list_bkg[0], lw=lw, fmt=fmt)\n",
    "    ax1.set_xlabel(xlabels[layer_names[0]])\n",
    "    ax1.set_ylabel(r'Output')    \n",
    "    \n",
    "if (Nlist > 1):\n",
    "    \n",
    "    ax2.errorbar(xvals_list[1], yvals_list[1], yerr=yerrs_list[1], lw=lw, fmt=fmt)\n",
    "    ax2.errorbar(xvals_list_bkg[1], yvals_list_bkg[1], yerr=yerrs_list_bkg[1], lw=lw, fmt=fmt)\n",
    "    ax2.set_xlabel(xlabels[layer_names[1]])\n",
    "    ax2.set_ylabel(r'Output')\n",
    "    \n",
    "if (Nlist > 2):\n",
    "    \n",
    "    ax3.errorbar(xvals_list[2], yvals_list[2], yerr=yerrs_list[2], lw=lw, fmt=fmt)\n",
    "    ax3.errorbar(xvals_list_bkg[2], yvals_list_bkg[2], yerr=yerrs_list_bkg[2], lw=lw, fmt=fmt)\n",
    "    ax3.set_xlabel(xlabels[layer_names[2]])\n",
    "    ax3.set_ylabel(r'Output')\n",
    "\n",
    "if (Nlist > 3):\n",
    "    \n",
    "    ax4.errorbar(xvals_list[3], yvals_list[3], yerr=yerrs_list[3], lw=lw, fmt=fmt)\n",
    "    ax4.errorbar(xvals_list_bkg[3], yvals_list_bkg[3], yerr=yerrs_list_bkg[3], lw=lw, fmt=fmt)\n",
    "    ax4.set_xlabel(xlabels[layer_names[3]])\n",
    "    ax4.set_ylabel(r'Output')\n",
    "    \n",
    "if (Nlist > 4):\n",
    "    \n",
    "    ax5.errorbar(xvals_list[4], yvals_list[4], yerr=yerrs_list[4], lw=lw, fmt=fmt)\n",
    "    ax5.errorbar(xvals_list_bkg[4], yvals_list_bkg[4], yerr=yerrs_list_bkg[4], lw=lw, fmt=fmt)\n",
    "    ax5.set_xlabel(xlabels[layer_names[4]])\n",
    "    ax5.set_ylabel(r'Output')\n",
    "    \n",
    "if (Nlist > 5):\n",
    "    \n",
    "    ax6.errorbar(xvals_list[5], yvals_list[5], yerr=yerrs_list[5], lw=lw, fmt=fmt)\n",
    "    ax6.errorbar(xvals_list_bkg[5], yvals_list_bkg[5], yerr=yerrs_list_bkg[5], lw=lw, fmt=fmt)\n",
    "    ax6.set_xlabel(xlabels[layer_names[5]])\n",
    "    ax6.set_ylabel(r'Output')   \n",
    "\n",
    "fig.legend(['Signal', 'Background'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "figname = 'plots/Lambda'+str(HPARAMS.Lambda)+'_scatterplots.png'\n",
    "plt.savefig(figname)\n",
    "print('saving '+figname)\n",
    "\n",
    "plt.suptitle(Title, fontsize=25)\n",
    "# plt.tight_layout()\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(rows,cols, figsize=(10,4*rows))\n",
    "\n",
    "plt.suptitle(Title, fontsize=25)\n",
    "\n",
    "xvals_list = []\n",
    "yvals_list = []\n",
    "yerrs_list = []\n",
    "\n",
    "xvals_list_bkg = []\n",
    "yvals_list_bkg = []\n",
    "yerrs_list_bkg = []\n",
    "\n",
    "\n",
    "yrange = [-0.05,1.05]\n",
    "\n",
    "for name in layer_names:\n",
    "    \n",
    "    x, y, e = get_prediction_yvalues(xvars[name], predict[:,1], norm=True)\n",
    "    xb, yb, eb = get_prediction_yvalues(xvars[name], predict[:,0], norm=True)\n",
    "    \n",
    "    xvals_list.append(x)\n",
    "    yvals_list.append(y)\n",
    "    yerrs_list.append(e)\n",
    "\n",
    "    xvals_list_bkg.append(xb)\n",
    "    yvals_list_bkg.append(yb)\n",
    "    yerrs_list_bkg.append(eb)\n",
    "    \n",
    "    \n",
    "    \n",
    "if (Nlist > 0):\n",
    "    if(Nlist < 2):\n",
    "        ax1 = ax[0]\n",
    "    elif(Nlist < 3):\n",
    "        ax1 = ax[0]\n",
    "    else:\n",
    "        ax1 = ax[0][0]\n",
    "        \n",
    "        \n",
    "if (Nlist > 1):\n",
    "    if(Nlist < 3):\n",
    "        ax2 = ax[1]\n",
    "    else:\n",
    "        ax2 = ax[0][1]\n",
    "        \n",
    "\n",
    "if (Nlist > 2): ax3 = ax[1][0]\n",
    "if (Nlist > 3): ax4 = ax[1][1]\n",
    "if (Nlist > 4): ax5 = ax[2][0]\n",
    "if (Nlist > 5): ax6 = ax[2][1]\n",
    "\n",
    "if (Nlist > 0):\n",
    "    \n",
    "    ax1.errorbar(xvals_list[0], yvals_list[0], yerr=yerrs_list[0], lw=lw, fmt=fmt)\n",
    "    ax1.errorbar(xvals_list_bkg[0], yvals_list_bkg[0], yerr=yerrs_list_bkg[0], lw=lw, fmt=fmt)\n",
    "    ax1.set_xlabel(xlabels[layer_names[0]])\n",
    "    ax1.set_ylabel(r'Normalized Output')\n",
    "    ax1.set_ylim(yrange)\n",
    "    \n",
    "if (Nlist > 1):\n",
    "    \n",
    "    ax2.errorbar(xvals_list[1], yvals_list[1], yerr=yerrs_list[1], lw=lw, fmt=fmt)\n",
    "    ax2.errorbar(xvals_list_bkg[1], yvals_list_bkg[1], yerr=yerrs_list_bkg[1], lw=lw, fmt=fmt)\n",
    "    ax2.set_xlabel(xlabels[layer_names[1]])\n",
    "    ax2.set_ylabel(r'Normalized Output')\n",
    "    ax2.set_ylim(yrange)\n",
    "    \n",
    "if (Nlist > 2):\n",
    "    \n",
    "    ax3.errorbar(xvals_list[2], yvals_list[2], yerr=yerrs_list[2], lw=lw, fmt=fmt)\n",
    "    ax3.errorbar(xvals_list_bkg[2], yvals_list_bkg[2], yerr=yerrs_list_bkg[2], lw=lw, fmt=fmt)\n",
    "    ax3.set_xlabel(xlabels[layer_names[2]])\n",
    "    ax3.set_ylabel(r'Normalized Output')\n",
    "    ax3.set_ylim(yrange)\n",
    "\n",
    "if (Nlist > 3):\n",
    "    \n",
    "    ax4.errorbar(xvals_list[3], yvals_list[3], yerr=yerrs_list[3], lw=lw, fmt=fmt)\n",
    "    ax4.errorbar(xvals_list_bkg[3], yvals_list_bkg[3], yerr=yerrs_list_bkg[3], lw=lw, fmt=fmt)\n",
    "    ax4.set_xlabel(xlabels[layer_names[3]])\n",
    "    ax4.set_ylabel(r'Normalized Output')\n",
    "    ax4.set_ylim(yrange)\n",
    "    \n",
    "if (Nlist > 4):\n",
    "    \n",
    "    ax5.errorbar(xvals_list[4], yvals_list[4], yerr=yerrs_list[4], lw=lw, fmt=fmt)\n",
    "    ax5.errorbar(xvals_list_bkg[4], yvals_list_bkg[4], yerr=yerrs_list_bkg[4], lw=lw, fmt=fmt)\n",
    "    ax5.set_xlabel(xlabels[layer_names[4]])\n",
    "    ax5.set_ylabel(r'Normalized Output')\n",
    "    ax5.set_ylim(yrange)\n",
    "    \n",
    "if (Nlist > 5):\n",
    "    \n",
    "    ax6.errorbar(xvals_list[5], yvals_list[5], yerr=yerrs_list[5], lw=lw, fmt=fmt)\n",
    "    ax6.errorbar(xvals_list_bkg[5], yvals_list_bkg[5], yerr=yerrs_list_bkg[5], lw=lw, fmt=fmt)\n",
    "    ax6.set_xlabel(xlabels[layer_names[5]])\n",
    "    ax6.set_ylabel(r'Normalized Output')\n",
    "    ax6.set_ylim(yrange)\n",
    "\n",
    "fig.legend(['Signal', 'Background'])\n",
    "# plt.tight_layout()\n",
    "\n",
    "\n",
    "\n",
    "figname = 'plots/Lambda'+str(HPARAMS.Lambda)+'_scatterplots_norm.png'\n",
    "plt.savefig(figname)\n",
    "print('saving '+figname)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Adversary Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rows=2\n",
    "cols=3\n",
    "\n",
    "fig, ax = plt.subplots(rows,cols, figsize=(15,7))\n",
    "\n",
    "if(HPARAMS.thetaBins > 0): plotBin(1, xvars['theta'], predict_adv, rows, cols)\n",
    "if(HPARAMS.thetaBins > 1): plotBin(2, xvars['theta'], predict_adv, rows, cols)\n",
    "if(HPARAMS.thetaBins > 2): plotBin(3, xvars['theta'], predict_adv, rows, cols)\n",
    "if(HPARAMS.thetaBins > 3): plotBin(4, xvars['theta'], predict_adv, rows, cols)\n",
    "if(HPARAMS.thetaBins > 4): plotBin(5, xvars['theta'], predict_adv, rows, cols)\n",
    "if(HPARAMS.thetaBins > 5): plotBin(6, xvars['theta'], predict_adv, rows, cols)\n",
    "\n",
    "plt.tight_layout()\n",
    "figname = 'plots/Adversary_Output.png'\n",
    "plt.savefig(figname)\n",
    "print('saving '+figname)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printTime(time.time()-start_notebook)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
