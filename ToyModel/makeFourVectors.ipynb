{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "import math\n",
    "import time\n",
    "import h5py\n",
    "import sklearn\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(783947328)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(\"data\"):\n",
    "    os.mkdir(\"data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Want arrayâ€™s of  [list of particle 4-vectors(pt, mass, eta, phi), z_leading, theta] to feed into RNN or 1D CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "addPerturbation = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition_exp(n_particles=10, nevents=1, mu=1.):\n",
    "    evals = np.random.exponential(scale = mu, size=(nevents,n_particles))\n",
    "    sumRow =np.repeat(evals.sum(axis=1), n_particles).reshape(nevents, n_particles)\n",
    "    evals = np.sort(np.divide(evals,sumRow))[:, ::-1]\n",
    "    return evals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeFourVectors(n_events = 10, n_particles = 5, isSignal = False, overlap = 0):\n",
    "    labels = np.zeros(shape=(n_events,2))\n",
    "    \n",
    "    zloc = 0.5\n",
    "    theta_loc = 0.2\n",
    "    tau_loc = 0.4\n",
    "    tau_loc2 = 0.3\n",
    "    pt_factor = 1.\n",
    "    if(addPerturbation):\n",
    "        zloc = 0.5\n",
    "        theta_loc = 0.1\n",
    "        tau_loc = 0.4\n",
    "        tau_loc2 = 0.3\n",
    "        pt_factor = 0.5\n",
    "    \n",
    "        # create input variables\n",
    "    if isSignal:\n",
    "        if (overlap==0):\n",
    "            theta = np.random.normal(loc=theta_loc, scale=0.02, size=n_events) # signal_d\n",
    "            z = np.random.normal(loc=zloc, scale=0.02, size=n_events) #signal_z \n",
    "            tau = np.random.exponential(scale=0.04, size=n_events)  # signal_tau\n",
    "            tautwo = np.random.exponential(scale=0.4, size=n_events)\n",
    "        elif(overlap==1):\n",
    "            theta = np.random.normal(loc=theta_loc, scale=0.03, size=n_events) # signal_d_littleoverlap\n",
    "            z = np.random.normal(loc=zloc, scale=0.09, size=n_events) #signal_z_littleoverlap\n",
    "            tau = np.random.exponential(scale=0.14, size=n_events)# signal_tau_littleoverlap\n",
    "            tautwo = np.random.exponential(scale=0.08, size=n_events)\n",
    "        elif(overlap==2):\n",
    "            theta = np.random.normal(loc=theta_loc, scale=0.05, size=n_events) # signal_d_overlap\n",
    "            z = np.random.normal(loc=zloc, scale=0.12, size=n_events) #signal_z_overlap\n",
    "            tau = np.random.exponential(scale=0.2, size=n_events) # signal_tau_overlap\n",
    "            tautwo = np.random.exponential(scale=0.1, size=n_events)\n",
    "        pt = np.random.exponential(scale = 1/0.01, size = (n_events, n_particles))*pt_factor\n",
    "        mass = 0.936*np.random.normal(loc = 39.5, scale = 18.3, size = (n_events,n_particles))\n",
    "        eta = 1.1*np.random.normal(loc = 0.0, scale = 1.4, size = (n_events,n_particles))\n",
    "        phi = np.random.uniform(-3.14,3.14,(n_events, n_particles))\n",
    "        labels[:,1]=1\n",
    "    else:\n",
    "        if (overlap==0):\n",
    "            theta = np.random.exponential(scale=0.02, size=n_events) # bkg_d\n",
    "            z = np.random.exponential(scale=0.02, size=n_events) #bkg_z\n",
    "            tau = np.random.exponential(scale=0.02, size=n_events) # bkg_b\n",
    "            tautwo = np.random.exponential(scale=0.02, size=n_events)\n",
    "        elif(overlap==1):\n",
    "            theta = np.random.exponential(scale=0.03, size=n_events) # bkg_d_littleoverlap\n",
    "            z = np.random.exponential(scale=0.1, size=n_events) #bkg_z_olittleverlap\n",
    "            tau = np.random.exponential(scale=0.07, size=n_events) # bkg_b_olittleverlap\n",
    "            tautwo = np.random.exponential(scale=0.04, size=n_events)\n",
    "        elif(overlap==2):\n",
    "            theta = np.random.exponential(scale=0.05, size=n_events) # bkg_d_overlap\n",
    "            z = np.random.exponential(scale=0.15, size=n_events) #bkg_z_overlap\n",
    "            tau = np.random.exponential(scale=0.1, size=n_events) # bkg_b_overlap\n",
    "            tautwo = np.random.exponential(scale=0.05, size=n_events)\n",
    "        pt = np.random.exponential(scale=1/0.002675, size = (n_events, n_particles))\n",
    "        mass = np.random.exponential(scale=1/0.011082, size = (n_events, n_particles))\n",
    "        eta = 1.008*np.random.normal(loc = 0.001913, scale = 1.811, size = (n_events, n_particles))\n",
    "        phi = np.random.uniform(-3.14,3.14,size = (n_events, n_particles))\n",
    "        labels[:,0]=1\n",
    "        \n",
    "        \n",
    "    print(labels)\n",
    "    \n",
    "    # masking z to ensure z<1.0\n",
    "    z = np.where(z<1.0, z, z%1) #signal_z   \n",
    "    # making so that z is always more than 1-z\n",
    "    z = np.where(z>0.5, z, (1-z))\n",
    "    \n",
    "    mass = np.where(mass>0., mass, mass+20.)\n",
    "    \n",
    "    z = np.repeat(z, n_particles).reshape(n_events, n_particles)\n",
    "    # masking theta to ensure theta<0.5\n",
    "    theta = np.where(theta<0.5, theta, theta%0.5)\n",
    "    theta = np.repeat(theta, n_particles).reshape(n_events, n_particles)\n",
    "    \n",
    "    # masking tau to ensure tau<0.7\n",
    "    tau = np.where(tau<0.5, tau, tau%0.7)\n",
    "    tau = np.repeat(tau, n_particles).reshape(n_events, n_particles)\n",
    "    \n",
    "    # masking tau to ensure tau<0.6\n",
    "    tautwo = np.where(tautwo<0.5, tautwo, tautwo%0.6)\n",
    "    tautwo = np.repeat(tautwo, n_particles).reshape(n_events, n_particles)\n",
    "    \n",
    "    # distributing pT fractions between particles\n",
    "    particles1 = np.multiply(partition_exp(n_particles, n_events), z)\n",
    "    particles2 = np.multiply(partition_exp(n_particles, n_events), (1-z))\n",
    "    \n",
    "    \n",
    "    # one jet has two subjets \n",
    "    radii = np.random.uniform(0.25,0.5 ,size = (n_events,2))\n",
    "    radii1 = np.array([np.multiply(np.ones(shape = int(n_particles/2)),y) for y in radii[:,0]])\n",
    "    radii2 = np.array([np.multiply(np.ones(shape = int(n_particles/2)),y) for y in radii[:,1]])\n",
    "    dtheta1 = np.random.exponential(scale=0.5, size=(n_events, int(n_particles/2))) # delta theta for first subjet\n",
    "    dtheta1= np.sort(np.where(dtheta1<radii1, dtheta1, dtheta1%radii1))\n",
    "    phi1 = np.random.uniform(0, 2*math.pi, size=(n_events, int(n_particles/2))) # angular\n",
    "    dtheta2 = np.random.exponential(scale=0.5, size=(n_events, int(n_particles/2))) # delta theta for second subjet\n",
    "    dtheta2= np.sort(np.where(dtheta2<radii2, dtheta2, dtheta2%radii2))\n",
    "    phi2 = np.random.uniform(0, 2*math.pi, size=(n_events, int(n_particles/2))) # angular\n",
    "    \n",
    "    z = z.reshape(n_events,n_particles)\n",
    "    theta = theta.reshape(n_events,n_particles)\n",
    "    tau = tau.reshape(n_events,n_particles)\n",
    "    tautwo = tautwo.reshape(n_events,n_particles)\n",
    "    radii = np.concatenate((radii1, radii2), axis = 1)\n",
    "    return pt, eta, mass, phi, radii, z, theta, tau, tautwo, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load some pythia data and fit to get idea of signal vs. background distribution to make a nice toy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_events = 10000\n",
    "n_particles = 10\n",
    "tic = time.perf_counter()\n",
    "isSignal1 = True\n",
    "overlap = 1\n",
    "pt1, eta1, mass1, phi1, radii1, z1, theta1, tau1, tautwo1, labels1 = makeFourVectors(n_events, n_particles, isSignal1, overlap)\n",
    "features1 = [pt1, eta1, mass1, phi1, radii1, z1, theta1, tau1, tautwo1]\n",
    "print(pt1.shape, mass1.shape, phi1.shape, radii1.shape, z1.shape, theta1.shape,tau1.shape, tautwo1.shape, labels1.shape)\n",
    "toc = time.perf_counter()\n",
    "print('Processing Time is ',toc-tic, 'seconds for ',n_events, ' samples.' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.perf_counter()\n",
    "isSignal2 = False\n",
    "pt2, eta2, mass2, phi2, radii2, z2, theta2, tau2, tautwo2, labels2= makeFourVectors(n_events, n_particles, isSignal2, overlap)\n",
    "features2 = [pt2, eta2, mass2, phi2, radii2, z2, theta2, tau2, tautwo2]\n",
    "toc = time.perf_counter()\n",
    "print('Processing Time is ',toc-tic, 'seconds for ',n_events, ' samples.' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [r'$p_T$', r'$\\eta$', r'$m_{const}$', r'$\\phi$', r'$r$', r'$z$', r'$\\theta$', r'$\\tau$',r'$\\tau$2' ]\n",
    "ptbin = np.arange(0,5000, 10)\n",
    "etabin = np.arange(-9, 9, 9/40)\n",
    "mbin = np.arange(-10,1000,10)\n",
    "phibin = np.arange(-np.pi, np.pi, np.pi/40)\n",
    "thetabin = np.arange(0, 1, 0.01)\n",
    "zbin = np.arange(0,1,0.01)\n",
    "rbin = np.arange(0.25,0.5, 0.01)\n",
    "taubin = np.arange(0,1,0.01)\n",
    "tautwobin = np.arange(0,1,0.01)\n",
    "bins = [ptbin, etabin, mbin, phibin, rbin, zbin, thetabin, taubin, tautwobin]\n",
    "plt.figure(figsize = (16,24))\n",
    "for i in np.arange(len(features1)):\n",
    "    plt.subplot(int(len(features1)/2)+1,2,(i+1))\n",
    "    hist1, bins1 = np.histogram(features1[i], bins=bins[i])\n",
    "    hist2, bins2 = np.histogram(features2[i], bins=bins1)\n",
    "    plt.bar(bins1[:-1], hist1/(np.sum(hist1)), width=np.diff(bins1), alpha = 0.5, label = \"Signal \" + names[i])\n",
    "    plt.bar(bins2[:-1], hist2/(np.sum(hist2)), width=np.diff(bins2), alpha = 0.5, label = \"Bkg \"+names[i])\n",
    "    plt.xlabel(names[i])\n",
    "    plt.ylabel(\"Fraction\")\n",
    "    legend = plt.legend()\n",
    "    plt.title(\"Toy Model \"+names[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.perf_counter()\n",
    "isSignal3 = True\n",
    "pt3, eta3, mass3, phi3, radii3, z3, theta3, tau3, tautwo3, labels3= makeFourVectors(n_events, n_particles, isSignal3, overlap)\n",
    "toc = time.perf_counter()\n",
    "fourvectors3 = np.array([pt3, eta3, mass3, phi3])\n",
    "fourvectors3 = fourvectors3.reshape(n_events, n_particles, 4)\n",
    "print('Processing Time is ',toc-tic, 'seconds for ',n_events, ' samples.' )\n",
    "np.savez('data/dummyvectors_sgn_test', pt = pt3, eta = eta3, phi = phi3, mass = mass3, radiilab = radii3, zlab = z3, thetalab = theta3, taulab = tau3, tautwolab = tautwo3, labels = labels3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.perf_counter()\n",
    "isSignal4 = False\n",
    "pt4, eta4, mass4, phi4, radii4, z4, theta4, tau4, tautwo4, labels4= makeFourVectors(n_events, n_particles, isSignal4, overlap)\n",
    "toc = time.perf_counter()\n",
    "fourvectors4 = np.array([pt4, eta4, mass4, phi4])\n",
    "fourvectors4 = fourvectors4.reshape(n_events, n_particles, 4)\n",
    "print('Processing Time is ',toc-tic, 'seconds for ',n_events, ' samples.' )\n",
    "np.savez('data/dummyvectors_bkg_test', pt = pt4, eta = eta4, phi = phi4, mass = mass4, radiilab = radii4, zlab = z4, thetalab = theta4, taulab = tau4 , tautwolab = tautwo4, labels = labels4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate signal and bg together, shuffle, and save files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainlabels = np.concatenate((labels1,labels2),axis=0)\n",
    "n_train = len(trainlabels)\n",
    "train_pt = np.concatenate((pt1, pt2), axis = 0)\n",
    "batch = np.size(train_pt, 1)\n",
    "train_pt = train_pt.reshape(n_train, batch, 1)\n",
    "train_eta = np.concatenate((eta1, eta2), axis = 0).reshape(n_train, batch, 1)\n",
    "train_phi = np.concatenate((phi1, phi2), axis = 0).reshape(n_train, batch, 1)\n",
    "train_mass = np.concatenate((mass1, mass2), axis = 0).reshape(n_train, batch, 1)\n",
    "train_r = np.concatenate((radii1, radii2), axis = 0)\n",
    "train_theta = np.concatenate((theta1, theta2), axis = 0)\n",
    "train_z = np.concatenate((z1, z2), axis = 0)\n",
    "train_tau = np.concatenate((tau1, tau2), axis = 0)\n",
    "train_tautwo = np.concatenate((tautwo1, tautwo2), axis = 0)\n",
    "train_labels = trainlabels.reshape(n_train, 2)\n",
    "# testing data\n",
    "testlabels = np.concatenate((labels3, labels4),axis=0)\n",
    "n_test = len(testlabels)\n",
    "test_pt = np.concatenate((pt3, pt4), axis = 0)\n",
    "batch = np.size(test_pt, 1)\n",
    "test_pt = test_pt.reshape(n_test, batch, 1)\n",
    "test_eta = np.concatenate((eta3, eta4), axis = 0).reshape(n_test, batch, 1)\n",
    "test_phi = np.concatenate((phi3, phi4), axis = 0).reshape(n_test, batch, 1)\n",
    "test_mass = np.concatenate((mass3, mass4), axis = 0).reshape(n_test, batch, 1)\n",
    "test_r = np.concatenate((radii3, radii4), axis = 0)\n",
    "test_theta = np.concatenate((theta3, theta4), axis = 0)\n",
    "test_z = np.concatenate((z3, z4), axis = 0)\n",
    "test_tau = np.concatenate((tau3, tau4), axis = 0)\n",
    "test_tautwo = np.concatenate((tautwo3, tautwo4), axis = 0)\n",
    "test_labels = testlabels.reshape(int(n_test), 2)\n",
    "print(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get indices\n",
    "train_ind = np.arange(len(train_labels[:,0]))\n",
    "test_ind = np.arange(len(test_labels[:,0]))\n",
    "print(train_ind)\n",
    "\n",
    "# shuffle indices\n",
    "np.random.shuffle(train_ind)\n",
    "np.random.shuffle(test_ind)\n",
    "print(train_ind)\n",
    "\n",
    "\n",
    "\n",
    "train_features = [train_pt, train_eta, train_phi, train_mass, train_theta, train_r, train_z, train_labels]\n",
    "test_features = [test_pt, test_eta, test_phi, test_mass, test_theta, test_r, test_z, test_labels]\n",
    "for i in np.arange(len(train_features)):\n",
    "    train_features[i] = train_features[i][train_ind]\n",
    "    test_features[i] = test_features[i][test_ind]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig = (train_features[-1][:,0]==0)\n",
    "bkg = (train_features[-1][:,0]==1)\n",
    "\n",
    "plt.hist(train_features[4][sig].flatten(), alpha=0.5)\n",
    "plt.hist(train_features[4][bkg].flatten(), alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ext = ''\n",
    "if(addPerturbation):\n",
    "    ext='_perturb'\n",
    "\n",
    "filename_train = 'data/jetConstTrain_overlap'+ext\n",
    "filename_test = 'data/jetConstTest_overlap'+ext\n",
    "\n",
    "np.savez(filename_train, pt = train_features[0], eta = train_features[1], phi = train_features[2], mass = train_features[3], thetalab = train_features[4], radiilab = train_features[5], zlab = train_features[6], labels = train_features[7])\n",
    "np.savez(filename_test, pt = test_features[0], eta = test_features[1], phi = test_features[2], mass = test_features[3], thetalab = test_features[4], radiilab = test_features[5], zlab = test_features[6], labels = test_features[7])\n",
    "\n",
    "print(filename_test+'.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
